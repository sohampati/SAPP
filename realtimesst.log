2024-12-14 17:09:50.706 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:09:50.717 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-12-14 17:09:50.722 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-12-14 17:09:50.723 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-12-14 17:09:57.782 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-12-14 17:09:57.950 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so, 0x0006): Library not loaded: @rpath/libavutil.58.dylib
  Referenced from: <BAD74526-9081-3418-B90A-AC970B145BF3> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.58.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.58.dylib' (no such file), '/usr/local/lib/libavutil.58.dylib' (no such file), '/usr/lib/libavutil.58.dylib' (no such file, not in dyld cache)
2024-12-14 17:09:57.953 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-12-14 17:09:58.114 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so, 0x0006): Library not loaded: @rpath/libavutil.57.dylib
  Referenced from: <671A0D0D-139F-3576-ABC0-4FB9CF3C3292> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.57.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.57.dylib' (no such file), '/usr/local/lib/libavutil.57.dylib' (no such file), '/usr/lib/libavutil.57.dylib' (no such file, not in dyld cache)
2024-12-14 17:09:58.114 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-12-14 17:09:58.290 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so, 0x0006): Library not loaded: @rpath/libavutil.56.dylib
  Referenced from: <D280808A-CCD9-399D-A66F-C62550FE7E86> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.56.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.56.dylib' (no such file), '/usr/local/lib/libavutil.56.dylib' (no such file), '/usr/lib/libavutil.56.dylib' (no such file, not in dyld cache)
2024-12-14 17:09:58.290 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-12-14 17:09:58.290 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-12-14 17:09:58.544 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-12-14 17:09:58.544 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-12-14 17:09:58.544 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-12-14 17:11:50.846 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-12-14 17:11:50.847 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-12-14 17:11:50.847 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:11:50.847 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:11:50.847 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:11:53.201 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:11:53.201 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:11:53.202 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:11:53.202 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:11:55.431 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:11:55.431 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:11:55.432 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:11:55.461 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:11:55.463 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:11:55.490 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:11:55.498 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:11:55.551 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:11:55.551 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:11:55.551 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:11:55.854 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:11:55.861 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.40 seconds
2024-12-14 17:11:55.861 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:11:55.861 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:12:12.656 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:12:12.658 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:12:12.660 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:12:12.660 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:12:12.661 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:12:12.662 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:12:12.679 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:12:13.386 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-12-14 17:12:13.386 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:12:13.386 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:12:13.386 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:12:14.375 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:12:14.375 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:12:14.376 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:12:14.376 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:12:46.766 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:12:46.768 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:12:46.770 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:12:46.858 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:12:46.861 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:12:46.872 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:12:46.887 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:12:48.717 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.86 seconds
2024-12-14 17:12:48.718 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:12:48.718 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:12:48.718 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:12:53.109 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:12:53.110 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:12:53.110 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:12:53.110 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:13:02.583 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:13:02.584 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:13:02.586 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:13:02.615 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:13:02.616 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:13:02.628 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:13:02.635 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:13:02.717 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:13:02.717 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:13:02.717 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:13:03.207 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:13:03.216 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.60 seconds
2024-12-14 17:13:03.216 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:13:03.216 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:13:07.689 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:13:07.690 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:13:07.691 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:13:07.691 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:13:07.692 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:13:07.693 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:13:07.716 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:13:08.352 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-12-14 17:13:08.352 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:13:08.352 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:13:08.353 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:13:08.455 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:13:08.455 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:13:08.455 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:13:08.455 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:13:32.142 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:13:32.144 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:13:32.146 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:13:32.248 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:13:32.250 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:13:32.253 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:13:32.279 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:13:34.519 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.27 seconds
2024-12-14 17:13:34.519 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:13:34.519 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:13:34.519 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:13:39.497 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:13:39.497 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:13:39.497 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:13:39.498 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:13:58.307 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:13:58.308 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:13:58.310 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:13:58.355 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:13:58.357 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:13:58.379 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:13:58.379 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:13:58.775 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:13:58.775 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:13:58.775 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:14:06.506 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:14:06.591 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 8.23 seconds
2024-12-14 17:14:06.591 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:06.591 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:14:08.109 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:14:08.109 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:08.110 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:14:08.111 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:14:08.112 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:14:08.112 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:14:08.126 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:14:09.181 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.07 seconds
2024-12-14 17:14:09.182 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:09.182 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:09.182 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:14:11.894 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:14:11.894 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:14:11.895 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:14:11.895 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:14:13.542 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:14:13.543 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:14:13.543 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:14:13.626 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:14:13.628 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:14:13.645 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:14:13.677 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:14:14.356 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.73 seconds
2024-12-14 17:14:14.356 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:14.356 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:14.356 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:14:15.837 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:14:15.838 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:14:15.838 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:14:15.838 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:14:17.188 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:14:17.189 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:14:17.190 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:14:17.230 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:14:17.232 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:14:17.256 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:14:17.256 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:14:17.643 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.41 seconds
2024-12-14 17:14:17.644 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:17.644 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:17.644 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:14:17.768 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:14:17.768 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:14:17.768 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:14:17.768 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:14:28.195 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:14:28.196 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:14:28.197 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:14:28.243 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:14:28.245 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:14:28.262 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:14:28.263 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:14:28.704 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:14:28.704 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:14:28.704 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:14:28.791 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:14:28.808 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.56 seconds
2024-12-14 17:14:28.808 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:28.809 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:14:30.052 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:14:30.052 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:30.053 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:14:30.053 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:14:30.055 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:14:30.055 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:14:30.056 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:14:30.140 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:14:30.140 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:14:30.140 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:14:30.450 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:14:30.534 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.48 seconds
2024-12-14 17:14:30.534 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:30.534 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:14:49.829 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:14:49.831 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:49.833 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:14:49.834 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:14:49.834 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:14:49.835 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:14:49.840 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:14:50.910 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.07 seconds
2024-12-14 17:14:50.910 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:50.910 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:50.910 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:14:55.151 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:14:55.151 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:14:55.152 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:14:55.152 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:14:59.490 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:14:59.491 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:14:59.491 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:14:59.521 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:14:59.523 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:14:59.526 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:14:59.558 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:14:59.920 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.40 seconds
2024-12-14 17:14:59.920 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:14:59.920 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:14:59.921 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:15:01.491 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:15:01.492 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:15:01.492 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:15:01.492 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:15:04.974 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-12-14 17:15:04.975 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-12-14 17:15:04.980 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-12-14 17:15:04.997 - RealTimeSTT: root - DEBUG - Receive from stdout pipe
2024-12-14 17:15:05.359 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-12-14 17:15:05.359 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-12-14 17:15:05.394 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-12-14 17:30:53.679 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:30:53.686 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-12-14 17:30:53.689 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-12-14 17:30:53.689 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-12-14 17:30:53.861 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-12-14 17:30:53.863 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so, 0x0006): Library not loaded: @rpath/libavutil.58.dylib
  Referenced from: <BAD74526-9081-3418-B90A-AC970B145BF3> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.58.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.58.dylib' (no such file), '/usr/local/lib/libavutil.58.dylib' (no such file), '/usr/lib/libavutil.58.dylib' (no such file, not in dyld cache)
2024-12-14 17:30:53.864 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-12-14 17:30:53.866 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so, 0x0006): Library not loaded: @rpath/libavutil.57.dylib
  Referenced from: <671A0D0D-139F-3576-ABC0-4FB9CF3C3292> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.57.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.57.dylib' (no such file), '/usr/local/lib/libavutil.57.dylib' (no such file), '/usr/lib/libavutil.57.dylib' (no such file, not in dyld cache)
2024-12-14 17:30:53.866 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-12-14 17:30:53.867 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so, 0x0006): Library not loaded: @rpath/libavutil.56.dylib
  Referenced from: <D280808A-CCD9-399D-A66F-C62550FE7E86> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.56.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.56.dylib' (no such file), '/usr/local/lib/libavutil.56.dylib' (no such file), '/usr/lib/libavutil.56.dylib' (no such file, not in dyld cache)
2024-12-14 17:30:53.867 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-12-14 17:30:53.867 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-12-14 17:30:53.935 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-12-14 17:30:53.936 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-12-14 17:30:53.936 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-12-14 17:30:57.156 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:30:57.950 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:34:22.387 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:34:22.394 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-12-14 17:34:22.397 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-12-14 17:34:22.398 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-12-14 17:34:22.566 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-12-14 17:34:22.568 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so, 0x0006): Library not loaded: @rpath/libavutil.58.dylib
  Referenced from: <BAD74526-9081-3418-B90A-AC970B145BF3> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.58.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.58.dylib' (no such file), '/usr/local/lib/libavutil.58.dylib' (no such file), '/usr/lib/libavutil.58.dylib' (no such file, not in dyld cache)
2024-12-14 17:34:22.569 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-12-14 17:34:22.571 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so, 0x0006): Library not loaded: @rpath/libavutil.57.dylib
  Referenced from: <671A0D0D-139F-3576-ABC0-4FB9CF3C3292> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.57.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.57.dylib' (no such file), '/usr/local/lib/libavutil.57.dylib' (no such file), '/usr/lib/libavutil.57.dylib' (no such file, not in dyld cache)
2024-12-14 17:34:22.571 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-12-14 17:34:22.572 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so, 0x0006): Library not loaded: @rpath/libavutil.56.dylib
  Referenced from: <D280808A-CCD9-399D-A66F-C62550FE7E86> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.56.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.56.dylib' (no such file), '/usr/local/lib/libavutil.56.dylib' (no such file), '/usr/lib/libavutil.56.dylib' (no such file, not in dyld cache)
2024-12-14 17:34:22.572 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-12-14 17:34:22.572 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-12-14 17:34:22.622 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-12-14 17:34:22.622 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-12-14 17:34:22.622 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-12-14 17:34:24.836 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-12-14 17:34:24.837 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-12-14 17:34:24.837 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:34:24.837 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:34:24.837 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:34:27.854 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:34:27.854 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:34:27.854 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:34:27.855 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:34:32.201 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:34:32.202 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:34:32.205 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:34:32.218 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:34:32.219 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:34:32.238 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:34:32.268 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:34:32.667 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.45 seconds
2024-12-14 17:34:32.667 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:34:32.667 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:34:32.668 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:34:34.195 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:34:34.196 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:34:34.196 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:34:34.196 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:34:37.448 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:34:37.448 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:34:37.449 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:34:37.489 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:34:37.491 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:34:37.494 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:34:37.518 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:34:38.192 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.70 seconds
2024-12-14 17:34:38.193 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:34:38.193 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:34:38.193 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:34:38.324 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-12-14 17:34:38.324 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-12-14 17:34:38.325 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-12-14 17:34:38.739 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-12-14 17:34:38.739 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-12-14 17:34:38.791 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-12-14 17:35:22.087 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:35:22.094 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-12-14 17:35:22.097 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-12-14 17:35:22.098 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-12-14 17:35:22.373 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-12-14 17:35:22.392 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so, 0x0006): Library not loaded: @rpath/libavutil.58.dylib
  Referenced from: <BAD74526-9081-3418-B90A-AC970B145BF3> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.58.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.58.dylib' (no such file), '/usr/local/lib/libavutil.58.dylib' (no such file), '/usr/lib/libavutil.58.dylib' (no such file, not in dyld cache)
2024-12-14 17:35:22.394 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-12-14 17:35:22.419 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so, 0x0006): Library not loaded: @rpath/libavutil.57.dylib
  Referenced from: <671A0D0D-139F-3576-ABC0-4FB9CF3C3292> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.57.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.57.dylib' (no such file), '/usr/local/lib/libavutil.57.dylib' (no such file), '/usr/lib/libavutil.57.dylib' (no such file, not in dyld cache)
2024-12-14 17:35:22.419 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-12-14 17:35:22.426 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so, 0x0006): Library not loaded: @rpath/libavutil.56.dylib
  Referenced from: <D280808A-CCD9-399D-A66F-C62550FE7E86> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.56.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.56.dylib' (no such file), '/usr/local/lib/libavutil.56.dylib' (no such file), '/usr/lib/libavutil.56.dylib' (no such file, not in dyld cache)
2024-12-14 17:35:22.426 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-12-14 17:35:22.426 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-12-14 17:35:22.538 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-12-14 17:35:22.538 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-12-14 17:35:22.538 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-12-14 17:35:24.377 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-12-14 17:35:24.377 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-12-14 17:35:24.377 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:35:24.377 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:35:24.378 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:35:25.501 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:35:25.501 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:35:25.501 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:35:25.502 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:35:28.957 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:35:28.958 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:35:28.959 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:35:28.964 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:35:28.966 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:35:28.992 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:35:29.029 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:35:29.402 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.44 seconds
2024-12-14 17:35:29.404 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2a71f31f0>, 'json_data': {'input': ['I have been considering. Can you tell me about it?\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:35:29.404 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:35:29.405 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:35:29.405 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:35:29.405 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:35:29.405 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:35:29.406 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:35:29.406 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:35:29.430 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a72042e0>
2024-12-14 17:35:29.430 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x2a69edf40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:35:29.449 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a71f7af0>
2024-12-14 17:35:29.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:35:29.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:35:29.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:35:29.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:35:29.449 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:35:29.933 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:35:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'60'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_9139931b3c3c1485c61feaf0a67b1132'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21aad59e5e1f9d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:35:29.935 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:35:29.935 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:35:29.936 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:35:29.936 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:35:29.936 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:35:29.937 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:35:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '60', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999975', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_9139931b3c3c1485c61feaf0a67b1132', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21aad59e5e1f9d-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:35:29.937 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_9139931b3c3c1485c61feaf0a67b1132
2024-12-14 17:35:30.250 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.771435738,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_1:Free consultation","score":0.764266729,"values":[],"metadata":{"original_data":"sales_process_1:Free consultation"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:35:34.529 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:35:34.529 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:35:34.529 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:35:34.529 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:35:37.850 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:35:37.851 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:35:37.852 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:35:37.875 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:35:37.877 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:35:37.886 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:35:37.919 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:35:38.297 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.42 seconds
2024-12-14 17:35:38.297 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2a71f3430>, 'json_data': {'input': ['I have been considering, can you tell me about it?\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:35:38.297 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:35:38.298 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:35:38.298 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:35:38.298 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:35:38.298 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:35:38.298 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:35:38.298 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:35:38.318 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a72081c0>
2024-12-14 17:35:38.318 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x2a69edf40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:35:38.340 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a71f7c40>
2024-12-14 17:35:38.340 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:35:38.341 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:35:38.341 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:35:38.341 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:35:38.341 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:35:38.636 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:35:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_250fda442352f9412799aca3ce9e24cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21ab0d2823bd52-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:35:38.638 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:35:38.638 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:35:38.639 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:35:38.639 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:35:38.640 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:35:38.640 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:35:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '115', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999975', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_250fda442352f9412799aca3ce9e24cc', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21ab0d2823bd52-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:35:38.640 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_250fda442352f9412799aca3ce9e24cc
2024-12-14 17:35:38.727 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.774364173,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_1:Free consultation","score":0.76612407,"values":[],"metadata":{"original_data":"sales_process_1:Free consultation"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:35:39.849 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:35:39.849 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:35:39.849 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:35:39.849 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:35:56.103 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:35:56.104 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:35:56.106 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:35:56.150 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:35:56.152 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:35:56.171 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:35:56.217 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:35:56.292 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:35:56.292 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:35:56.292 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:35:56.831 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:35:56.902 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.75 seconds
2024-12-14 17:35:56.903 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2a71f3790>, 'json_data': {'input': ["Conversation history not defined. How is that not the one lines it? 26, 26, in modern terms. The lucky hasn't been defined.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:35:56.903 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:35:56.904 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:35:56.904 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:35:56.904 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:35:56.904 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:35:56.904 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:35:56.924 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a7216ca0>
2024-12-14 17:35:56.924 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x2a69edf40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:35:56.948 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a7216a00>
2024-12-14 17:35:56.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:35:56.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:35:56.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:35:56.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:35:56.948 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:35:57.228 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:35:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'70'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999956'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_8adaecc7a951899a614d6da4c7665cf3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21ab817facbf7a-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:35:57.230 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:35:57.230 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:35:57.232 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:35:57.232 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:35:57.232 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:35:57.233 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:35:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '70', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999956', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_8adaecc7a951899a614d6da4c7665cf3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21ab817facbf7a-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:35:57.233 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_8adaecc7a951899a614d6da4c7665cf3
2024-12-14 17:35:57.333 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_0:Initial contact","score":0.753484786,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}},{"id":"products_0.efficiency:22","score":0.745678246,"values":[],"metadata":{"original_data":"products_0.efficiency:22"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:35:58.842 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:35:58.843 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:35:58.843 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:35:58.844 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:35:58.845 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:35:58.845 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:35:58.846 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:35:59.249 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.40 seconds
2024-12-14 17:35:59.249 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2a71f39d0>, 'json_data': {'input': ['Where do we define it here?\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:35:59.249 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:35:59.249 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:35:59.250 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:35:59.250 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:35:59.250 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:35:59.250 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:35:59.250 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:35:59.250 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:35:59.250 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:35:59.731 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:35:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999980'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_0cb838ca425eb845dd30a25015443204'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21ab8fef7dbf7a-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:35:59.733 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:35:59.733 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:35:59.734 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:35:59.735 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:35:59.735 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:35:59.735 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:35:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '109', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999980', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_0cb838ca425eb845dd30a25015443204', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21ab8fef7dbf7a-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:35:59.735 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_0cb838ca425eb845dd30a25015443204
2024-12-14 17:35:59.898 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.759880662,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_0:Initial contact","score":0.751349211,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:36:00.072 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:36:00.073 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:36:00.073 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:36:00.073 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:36:02.812 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:36:02.812 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:36:02.814 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:36:02.885 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:36:02.887 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:36:02.890 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:36:02.956 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:36:04.127 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.24 seconds
2024-12-14 17:36:04.127 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2a71f3ca0>, 'json_data': {'input': ['You can throw off that bitch.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:36:04.127 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:36:04.128 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:36:04.128 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:36:04.128 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:36:04.128 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:36:04.128 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:36:04.128 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:36:04.129 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:36:04.129 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:36:04.624 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:36:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'170'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999980'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_289d54e4672d29b910c4762c91db6122'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21abae6862bf7a-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:36:04.626 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:36:04.626 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:36:04.627 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:36:04.627 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:36:04.627 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:36:04.627 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:36:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '170', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999980', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_289d54e4672d29b910c4762c91db6122', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21abae6862bf7a-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:36:04.627 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_289d54e4672d29b910c4762c91db6122
2024-12-14 17:36:04.688 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"customer_benefits.average_bill_reduction_percentage:80","score":0.745717943,"values":[],"metadata":{"original_data":"customer_benefits.average_bill_reduction_percentage:80"}},{"id":"sales_process_3:Roof assessment","score":0.74390018,"values":[],"metadata":{"original_data":"sales_process_3:Roof assessment"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:36:06.643 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:36:06.643 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:36:06.643 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:36:06.644 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:36:09.155 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:36:09.155 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:36:09.156 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:36:09.239 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:36:09.241 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:36:09.248 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:36:09.269 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:36:11.034 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.79 seconds
2024-12-14 17:36:11.034 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2a71f3ee0>, 'json_data': {'input': ['Oh, shit. Okay. Enjoy me, sir.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:36:11.034 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:36:11.035 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:36:11.035 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:36:11.035 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:36:11.035 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:36:11.035 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:36:11.035 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:36:11.053 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a7216b20>
2024-12-14 17:36:11.053 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x2a69edf40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:36:11.076 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a7204b20>
2024-12-14 17:36:11.076 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:36:11.076 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:36:11.076 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:36:11.076 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:36:11.076 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:36:11.077 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:36:11.077 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:36:11.077 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:36:11.077 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:36:11.218 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:36:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'70'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999980'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_8f8c24542698e1b5a48f33cba8361952'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21abd9cb6453b1-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:36:11.219 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:36:11.219 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:36:11.220 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:36:11.220 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:36:11.220 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:36:11.220 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:36:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '70', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999980', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_8f8c24542698e1b5a48f33cba8361952', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21abd9cb6453b1-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:36:11.221 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_8f8c24542698e1b5a48f33cba8361952
2024-12-14 17:36:11.279 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.755796552,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_0:Initial contact","score":0.755508542,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:37:12.890 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:37:12.891 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:37:12.896 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:37:12.911 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:37:12.915 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:37:12.952 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:37:12.957 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:37:14.655 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.74 seconds
2024-12-14 17:37:14.655 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2a7212040>, 'json_data': {'input': ["Oh, because it's good, I split it into two different methods, you know what I'm saying? So, no, I just passed the conversation history through as a parameter. So programming. Wait, but I don't know how to do that, because it's like, it's like this. I guess I can make conversation history a goal. Wait, that makes sense, the conversation history should be a goal of it. I don't say about that. I don't know how to do that.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:37:14.655 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:37:14.655 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:37:14.656 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:37:14.656 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:37:14.656 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:37:14.656 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:37:14.656 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:37:14.710 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a72115b0>
2024-12-14 17:37:14.710 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x2a69edf40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:37:14.729 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2a7211040>
2024-12-14 17:37:14.729 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:37:14.729 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:37:14.729 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:37:14.729 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:37:14.729 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:37:15.009 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:37:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'72'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999882'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_edf8e5db5dda20c52dd4dbd548e93172'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21ad6798226753-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:37:15.011 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:37:15.011 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:37:15.013 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:37:15.014 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:37:15.014 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:37:15.014 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:37:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '72', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999882', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '7ms', 'x-request-id': 'req_edf8e5db5dda20c52dd4dbd548e93172', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21ad6798226753-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:37:15.014 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_edf8e5db5dda20c52dd4dbd548e93172
2024-12-14 17:37:15.272 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.745821,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_0:Initial contact","score":0.741283,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:37:21.340 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-12-14 17:37:21.341 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-12-14 17:37:21.344 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-12-14 17:37:21.391 - RealTimeSTT: root - DEBUG - Receive from stdout pipe
2024-12-14 17:37:21.698 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-12-14 17:37:21.698 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-12-14 17:37:21.746 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-12-14 17:39:47.917 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:39:47.924 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-12-14 17:39:47.927 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-12-14 17:39:47.927 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-12-14 17:39:48.058 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-12-14 17:39:48.060 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so, 0x0006): Library not loaded: @rpath/libavutil.58.dylib
  Referenced from: <BAD74526-9081-3418-B90A-AC970B145BF3> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.58.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.58.dylib' (no such file), '/usr/local/lib/libavutil.58.dylib' (no such file), '/usr/lib/libavutil.58.dylib' (no such file, not in dyld cache)
2024-12-14 17:39:48.061 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-12-14 17:39:48.063 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so, 0x0006): Library not loaded: @rpath/libavutil.57.dylib
  Referenced from: <671A0D0D-139F-3576-ABC0-4FB9CF3C3292> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.57.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.57.dylib' (no such file), '/usr/local/lib/libavutil.57.dylib' (no such file), '/usr/lib/libavutil.57.dylib' (no such file, not in dyld cache)
2024-12-14 17:39:48.063 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-12-14 17:39:48.064 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so, 0x0006): Library not loaded: @rpath/libavutil.56.dylib
  Referenced from: <D280808A-CCD9-399D-A66F-C62550FE7E86> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.56.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.56.dylib' (no such file), '/usr/local/lib/libavutil.56.dylib' (no such file), '/usr/lib/libavutil.56.dylib' (no such file, not in dyld cache)
2024-12-14 17:39:48.064 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-12-14 17:39:48.064 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-12-14 17:39:48.117 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-12-14 17:39:48.118 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-12-14 17:39:48.118 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-12-14 17:39:50.207 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-12-14 17:39:50.207 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-12-14 17:39:50.207 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:39:50.207 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:39:50.208 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:39:55.744 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:39:55.745 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:39:55.745 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:39:55.745 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:39:59.459 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:39:59.459 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:39:59.461 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:39:59.534 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:39:59.536 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:39:59.561 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:39:59.596 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:00.002 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.47 seconds
2024-12-14 17:40:00.004 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a1051f0>, 'json_data': {'input': ['Yeah, I would love to learn about how it would fit into my home.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:00.004 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:00.005 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:00.005 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:00.005 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:40:00.005 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:40:00.005 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:40:00.006 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:40:00.028 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a1190a0>
2024-12-14 17:40:00.028 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:40:00.054 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a10ad60>
2024-12-14 17:40:00.054 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:00.054 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:00.054 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:00.054 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:00.054 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:00.302 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999972'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_636e78402fb9f0b5d606e3f005b9b7e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b170e8e844d0-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:00.303 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:00.304 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:00.305 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:00.305 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:00.305 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:00.305 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '115', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999972', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_636e78402fb9f0b5d606e3f005b9b7e5', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b170e8e844d0-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:00.305 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_636e78402fb9f0b5d606e3f005b9b7e5
2024-12-14 17:40:00.597 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"system_compatibility.smart_home_integrations_2:Home energy management systems","score":0.78446877,"values":[],"metadata":{"original_data":"system_compatibility.smart_home_integrations_2:Home energy management systems"}},{"id":"sales_process_2:Energy usage analysis","score":0.782392383,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:03.499 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:03.499 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:03.499 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:40:03.500 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:40:06.816 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:40:06.816 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:40:06.817 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:40:06.887 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:40:06.890 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:40:06.891 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:06.895 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:40:07.351 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.46 seconds
2024-12-14 17:40:07.351 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a1054c0>, 'json_data': {'input': ['Do our coat is so bad our coat is so bad.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:07.352 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:07.352 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:07.352 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:07.352 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:40:07.352 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:40:07.352 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:40:07.353 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:40:07.372 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a11f2e0>
2024-12-14 17:40:07.372 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:40:07.396 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a119fd0>
2024-12-14 17:40:07.397 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:07.397 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:07.397 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:07.397 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:07.397 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:07.844 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'76'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999977'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_0c0c258792ef779be2fccd86894f1f3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b19ecf01bf64-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:07.845 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:07.846 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:07.847 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:07.847 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:07.847 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:07.847 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '76', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999977', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_0c0c258792ef779be2fccd86894f1f3e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b19ecf01bf64-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:07.848 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_0c0c258792ef779be2fccd86894f1f3e
2024-12-14 17:40:07.988 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_3:Roof assessment","score":0.764986157,"values":[],"metadata":{"original_data":"sales_process_3:Roof assessment"}},{"id":"products_0.degradation_rate:0.5","score":0.764116228,"values":[],"metadata":{"original_data":"products_0.degradation_rate:0.5"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:09.625 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:09.625 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:09.626 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:40:09.626 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:40:10.859 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:40:10.859 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:40:10.860 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:40:10.861 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:40:10.863 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:40:10.872 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:40:10.928 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:12.085 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.22 seconds
2024-12-14 17:40:12.085 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a1054c0>, 'json_data': {'input': ["J'ai trouv ce qu'est--dire.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:12.085 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:12.085 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:12.086 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:12.086 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:12.086 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:12.086 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:12.086 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:40:12.086 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:12.086 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:12.756 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'423'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999980'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_aa5e42f590887056fef435625df1f087'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b1bc19d0bf64-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:12.762 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:12.763 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:12.764 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:12.764 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:12.764 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:12.764 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '423', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999980', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_aa5e42f590887056fef435625df1f087', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b1bc19d0bf64-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:12.764 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_aa5e42f590887056fef435625df1f087
2024-12-14 17:40:12.937 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.758613586,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"products_1.efficiency:18","score":0.744331121,"values":[],"metadata":{"original_data":"products_1.efficiency:18"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:12.972 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:12.972 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:12.972 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:40:12.973 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:40:20.329 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:40:20.330 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:40:20.330 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:40:20.338 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:40:20.340 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:40:20.352 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:40:20.398 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:20.955 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-12-14 17:40:20.955 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a1058b0>, 'json_data': {'input': ["No, we can't make the model like this, right? Ah, this might be a time for another day.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:20.955 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:20.955 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:20.955 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:20.955 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:40:20.956 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:40:20.956 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:40:20.956 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:40:20.976 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a1256d0>
2024-12-14 17:40:20.976 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:40:20.999 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a125430>
2024-12-14 17:40:20.999 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:21.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:21.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:21.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:21.000 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:21.655 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'151'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999965'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_398f52a0a810c02e562f8bae1c9b43a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b1f3ccdcbf9d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:21.656 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:21.657 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:21.658 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:21.658 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:21.658 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:21.658 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '151', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999965', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_398f52a0a810c02e562f8bae1c9b43a0', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b1f3ccdcbf9d-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:21.658 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_398f52a0a810c02e562f8bae1c9b43a0
2024-12-14 17:40:21.768 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.774123251,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"products_2.efficiency:12","score":0.761838615,"values":[],"metadata":{"original_data":"products_2.efficiency:12"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:25.442 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:25.444 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:25.444 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:40:25.444 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:40:28.717 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:40:28.717 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:40:28.719 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:40:28.745 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:40:28.747 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:40:28.757 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:40:28.785 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:29.299 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.55 seconds
2024-12-14 17:40:29.300 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a105af0>, 'json_data': {'input': ["But we're there, we just don't know how to kill, we're just like near code in.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:29.300 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:29.300 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:29.300 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:29.301 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:40:29.301 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:40:29.301 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:40:29.301 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:40:29.325 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a1278b0>
2024-12-14 17:40:29.325 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:40:29.350 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a127970>
2024-12-14 17:40:29.350 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:29.350 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:29.350 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:29.350 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:29.350 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:29.758 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'193'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999968'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_2c3b690c3d1396a98e6be8001b4c5eb4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b22809ceadc5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:29.763 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:29.763 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:29.764 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:29.765 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:29.765 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:29.765 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '193', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999968', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_2c3b690c3d1396a98e6be8001b4c5eb4', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b22809ceadc5-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:29.765 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_2c3b690c3d1396a98e6be8001b4c5eb4
2024-12-14 17:40:29.853 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"products_2.efficiency:12","score":0.747780144,"values":[],"metadata":{"original_data":"products_2.efficiency:12"}},{"id":"products_0.efficiency:22","score":0.747619867,"values":[],"metadata":{"original_data":"products_0.efficiency:22"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:30.686 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:30.686 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:30.686 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:40:30.686 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:40:36.401 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:40:36.401 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:40:36.402 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:40:36.405 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:40:36.407 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:40:36.410 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:40:36.445 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:37.082 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.68 seconds
2024-12-14 17:40:37.083 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a105d30>, 'json_data': {'input': ["At that point we don't need just why do we even need to have a model variable I don't want to just put GPT for many of those now.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:37.083 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:37.083 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:37.083 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:37.083 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:40:37.084 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:40:37.084 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:40:37.084 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:40:37.110 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a13ab20>
2024-12-14 17:40:37.110 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:40:37.132 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a13a5e0>
2024-12-14 17:40:37.132 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:37.132 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:37.132 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:37.132 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:37.132 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:37.606 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:37.606 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:37.606 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:40:37.606 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:40:39.652 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:40:39.652 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:40:39.653 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:40:39.698 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:40:39.699 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:40:39.701 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:40:39.721 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:39.787 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:39.787 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:39.787 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:40:39.805 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'181'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999955'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_c077dd9a53bf465286ab16857b2ad609'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b258ae46bffb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:39.806 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:39.806 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:39.809 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:39.809 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:39.809 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:39.809 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '181', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999955', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_c077dd9a53bf465286ab16857b2ad609', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b258ae46bffb-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:39.809 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_c077dd9a53bf465286ab16857b2ad609
2024-12-14 17:40:39.868 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.753972411,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"customer_benefits.equivalent_trees_planted:1500","score":0.743385196,"values":[],"metadata":{"original_data":"customer_benefits.equivalent_trees_planted:1500"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:40.127 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:40:40.185 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.49 seconds
2024-12-14 17:40:40.186 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a105d30>, 'json_data': {'input': ["Oh, that's a model is? Yeah.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:40.186 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:40.186 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:40.186 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:40:40.186 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:40.186 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:40.186 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:40.187 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:40.187 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:40.720 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'70'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999981'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_6f2cc07f8b2224ace375436343f9aa9d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b26e3f59bffb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:40.722 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:40.722 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:40.723 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:40.724 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:40.724 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:40.724 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '70', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999981', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_6f2cc07f8b2224ace375436343f9aa9d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b26e3f59bffb-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:40.724 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_6f2cc07f8b2224ace375436343f9aa9d
2024-12-14 17:40:40.773 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.767689884,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"products_0.dimensions:77 x 39 inches","score":0.766501427,"values":[],"metadata":{"original_data":"products_0.dimensions:77 x 39 inches"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:55.324 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:40:55.325 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:55.326 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:40:55.326 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:40:55.328 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:40:55.330 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:40:55.359 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:40:56.498 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.17 seconds
2024-12-14 17:40:56.499 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a126310>, 'json_data': {'input': ["This is a bullshit, we don't need to make it global, but that should be a global. Why should we go with it? We only call it once, like we only need to set a decoder. I don't know the cleaner code itself, so we can change it once we change it. Let's do it. Okay, okay, fair, fair, fair. But I just want to make sure.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:40:56.499 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:40:56.499 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:40:56.499 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:40:56.500 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:40:56.500 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:40:56.500 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:40:56.500 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:40:56.652 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a13b970>
2024-12-14 17:40:56.653 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:40:56.681 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a145070>
2024-12-14 17:40:56.682 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:40:56.683 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:40:56.683 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:40:56.683 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:40:56.683 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:40:56.812 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:40:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'62'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999909'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_45f6e35c897932d9e7af439833eb00f4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b2d2d85dbffb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:40:56.814 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:40:56.815 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:40:56.816 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:40:56.816 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:40:56.817 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:40:56.817 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:40:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '62', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999909', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '5ms', 'x-request-id': 'req_45f6e35c897932d9e7af439833eb00f4', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b2d2d85dbffb-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:40:56.817 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_45f6e35c897932d9e7af439833eb00f4
2024-12-14 17:40:56.880 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"customer_benefits.average_bill_reduction_percentage:80","score":0.720120728,"values":[],"metadata":{"original_data":"customer_benefits.average_bill_reduction_percentage:80"}},{"id":"products_0.efficiency:22","score":0.715286672,"values":[],"metadata":{"original_data":"products_0.efficiency:22"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:40:58.087 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:40:58.087 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:40:58.087 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:40:58.088 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:41:01.151 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:41:01.151 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:41:01.152 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:41:01.171 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:41:01.173 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:41:01.199 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:41:01.219 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:41:01.569 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.40 seconds
2024-12-14 17:41:01.569 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a126550>, 'json_data': {'input': ['Oh shit. How do you brah?\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:41:01.569 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:41:01.570 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:41:01.570 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:41:01.570 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:41:01.570 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:41:01.570 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:41:01.570 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:41:01.571 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:41:01.571 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:41:01.664 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:41:01.664 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:41:01.664 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:41:01.664 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:41:01.705 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:41:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'45'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999981'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_aea1420d5661188e2df7ec45da3bf2d3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b2f16c2abffb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:41:01.706 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:41:01.706 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:41:01.706 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:41:01.706 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:41:01.706 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:41:01.706 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:41:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '45', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999981', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_aea1420d5661188e2df7ec45da3bf2d3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b2f16c2abffb-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:41:01.707 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_aea1420d5661188e2df7ec45da3bf2d3
2024-12-14 17:41:01.765 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_3:Roof assessment","score":0.753133118,"values":[],"metadata":{"original_data":"sales_process_3:Roof assessment"}},{"id":"sales_process_0:Initial contact","score":0.752784073,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:41:06.725 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:41:06.726 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:41:06.727 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:41:06.806 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:41:06.808 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:41:06.813 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:41:06.866 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:41:07.325 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.52 seconds
2024-12-14 17:41:07.326 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a126790>, 'json_data': {'input': ['I understand you use them. Okay. You had to click the eye to start.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:41:07.326 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:41:07.326 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:41:07.326 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:41:07.327 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:41:07.327 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:41:07.327 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:41:07.327 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:41:07.344 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a1574f0>
2024-12-14 17:41:07.344 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:41:07.368 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a1570d0>
2024-12-14 17:41:07.368 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:41:07.368 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:41:07.368 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:41:07.368 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:41:07.368 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:41:07.551 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:41:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'72'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999971'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_a8956eab62f03674d7ce366766612c1e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b3159818dd1c-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:41:07.552 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:41:07.552 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:41:07.553 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:41:07.553 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:41:07.553 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:41:07.553 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:41:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '72', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999971', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_a8956eab62f03674d7ce366766612c1e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b3159818dd1c-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:41:07.553 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_a8956eab62f03674d7ce366766612c1e
2024-12-14 17:41:07.618 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_0:Initial contact","score":0.760536134,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}},{"id":"sales_process_2:Energy usage analysis","score":0.756860435,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:41:07.630 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:41:07.630 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:41:07.630 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:41:07.630 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:41:08.770 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:41:08.770 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:41:08.771 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:41:08.806 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:41:08.808 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:41:08.823 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:41:08.839 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:41:09.211 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.40 seconds
2024-12-14 17:41:09.211 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a1269d0>, 'json_data': {'input': ['Thank you.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:41:09.212 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:41:09.212 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:41:09.212 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:41:09.212 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:41:09.212 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:41:09.212 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:41:09.213 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:41:09.213 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:41:09.213 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:41:09.434 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:41:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999984'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_bb00f1a09d9633650364c75d65f01f77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b3212e4cdd1c-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:41:09.436 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:41:09.436 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:41:09.437 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:41:09.438 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:41:09.438 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:41:09.438 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:41:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '115', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999984', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_bb00f1a09d9633650364c75d65f01f77', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b3212e4cdd1c-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:41:09.438 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_bb00f1a09d9633650364c75d65f01f77
2024-12-14 17:41:09.495 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.778216422,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_0:Initial contact","score":0.772095144,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:41:24.906 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:41:24.908 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:41:24.908 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:41:24.908 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:41:26.369 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:41:26.369 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:41:26.370 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:41:26.389 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:41:26.390 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:41:26.391 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:41:26.438 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:41:26.506 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:41:26.507 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:41:26.507 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:41:27.344 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:41:27.431 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.04 seconds
2024-12-14 17:41:27.431 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x16a126d30>, 'json_data': {'input': ['Thank you very much.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:41:27.432 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:41:27.432 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:41:27.432 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:41:27.432 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:41:27.432 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:41:27.432 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:41:27.457 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a127e50>
2024-12-14 17:41:27.457 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15bde3f40> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:41:27.484 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a13aaf0>
2024-12-14 17:41:27.484 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:41:27.484 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:41:27.485 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:41:27.485 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:41:27.485 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:41:27.623 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:41:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'73'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999982'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_269066bb0f910b0a91935bd6f86f6aff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b39358c0b03b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:41:27.625 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:41:27.625 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:41:27.626 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:41:27.626 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:41:27.626 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:41:27.626 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:41:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '73', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999982', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_269066bb0f910b0a91935bd6f86f6aff', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b39358c0b03b-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:41:27.626 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_269066bb0f910b0a91935bd6f86f6aff
2024-12-14 17:41:27.686 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.777130842,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_0:Initial contact","score":0.772123516,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:41:27.949 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-12-14 17:41:27.950 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-12-14 17:41:27.959 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-12-14 17:41:28.338 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-12-14 17:41:28.339 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-12-14 17:41:28.379 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-12-14 17:42:14.549 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:42:14.555 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-12-14 17:42:14.557 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-12-14 17:42:14.558 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-12-14 17:42:14.812 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-12-14 17:42:14.814 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so, 0x0006): Library not loaded: @rpath/libavutil.58.dylib
  Referenced from: <BAD74526-9081-3418-B90A-AC970B145BF3> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.58.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.58.dylib' (no such file), '/usr/local/lib/libavutil.58.dylib' (no such file), '/usr/lib/libavutil.58.dylib' (no such file, not in dyld cache)
2024-12-14 17:42:14.816 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-12-14 17:42:14.817 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so, 0x0006): Library not loaded: @rpath/libavutil.57.dylib
  Referenced from: <671A0D0D-139F-3576-ABC0-4FB9CF3C3292> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.57.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.57.dylib' (no such file), '/usr/local/lib/libavutil.57.dylib' (no such file), '/usr/lib/libavutil.57.dylib' (no such file, not in dyld cache)
2024-12-14 17:42:14.817 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-12-14 17:42:14.845 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so, 0x0006): Library not loaded: @rpath/libavutil.56.dylib
  Referenced from: <D280808A-CCD9-399D-A66F-C62550FE7E86> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.56.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.56.dylib' (no such file), '/usr/local/lib/libavutil.56.dylib' (no such file), '/usr/lib/libavutil.56.dylib' (no such file, not in dyld cache)
2024-12-14 17:42:14.845 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-12-14 17:42:14.845 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-12-14 17:42:14.950 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-12-14 17:42:14.951 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-12-14 17:42:14.951 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-12-14 17:42:16.817 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-12-14 17:42:16.817 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-12-14 17:42:16.817 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:42:16.817 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:42:16.818 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:42:18.862 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:42:18.863 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:42:18.863 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:42:18.863 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:42:23.784 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:42:23.786 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:42:23.787 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:42:23.865 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:42:23.867 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:42:23.875 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:42:23.929 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:42:24.305 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.44 seconds
2024-12-14 17:42:24.307 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2af25f160>, 'json_data': {'input': ['I am looking for some more information about a solar panel.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:42:24.307 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:42:24.307 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:42:24.307 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:42:24.308 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:42:24.308 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:42:24.308 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:42:24.309 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:42:24.330 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2af26b070>
2024-12-14 17:42:24.330 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x2ac215040> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:42:24.354 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2af259d30>
2024-12-14 17:42:24.354 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:24.354 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:24.354 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:24.354 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:24.354 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:24.855 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'294'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999972'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_c40905e2564219a67a5bab9eedba4f58'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b4f6cf4a7bb7-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:24.857 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:42:24.857 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:24.858 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:24.859 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:24.859 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:24.859 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '294', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999972', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_c40905e2564219a67a5bab9eedba4f58', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b4f6cf4a7bb7-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:24.859 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_c40905e2564219a67a5bab9eedba4f58
2024-12-14 17:42:25.114 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"financing_options_1:Solar Loan","score":0.821974814,"values":[],"metadata":{"original_data":"financing_options_1:Solar Loan"}},{"id":"products_0.name:SunWave MonoPlus Panels","score":0.817756,"values":[],"metadata":{"original_data":"products_0.name:SunWave MonoPlus Panels"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:42:25.124 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a sales rep for a particular Solar panel installation agency. You will initiate a sales conversation with a customer. Speak like a sales agent actually would on the phone. Only use company information given to you alongside the question by the user. Be persuasive but simple in your responses. The goal is to be personalable and helpful to the client in order to sell the companies product'}, {'role': 'assistant', 'content': "Hello! This is [Your Name] from [Your Company Name]. How are you doing today?\n\nI wanted to reach out because I see you're interested in solar panel installation, and I'm here to help you with all your questions and needs. More and more homeowners are making the switch to solar, and it can save you significantly on energy bills while also benefiting the environment.  \n\nWhat specific information are you looking for about our solar panel services?"}, {'role': 'user', 'content': 'I am looking for some more information about a solar panel.\n Use the following data to assist in your reponse:financing_options_1:Solar Loanproducts_0.name:SunWave MonoPlus Panels'}], 'model': 'gpt-4o-mini'}}
2024-12-14 17:42:25.124 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 17:42:25.125 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:25.125 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:25.125 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:25.125 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:25.125 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:27.312 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'1976'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199725'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'82ms'), (b'x-request-id', b'req_2d88f1db9422aa52bdd3a97cec8460bd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b4fb9cb47bb7-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:27.313 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 17:42:27.314 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:27.315 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:27.315 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:27.315 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:27.316 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '1976', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199725', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '82ms', 'x-request-id': 'req_2d88f1db9422aa52bdd3a97cec8460bd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b4fb9cb47bb7-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:27.316 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_2d88f1db9422aa52bdd3a97cec8460bd
2024-12-14 17:42:36.466 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:42:36.467 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:42:36.468 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:42:36.468 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:42:40.180 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:42:40.181 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:42:40.182 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:42:40.246 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:42:40.248 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:42:40.252 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:42:40.296 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:42:40.749 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.50 seconds
2024-12-14 17:42:40.749 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2af25f430>, 'json_data': {'input': ["It doesn't say, it doesn't say, we don't, we don't turn out.\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:42:40.749 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:42:40.750 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:42:40.750 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:42:40.750 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:42:40.750 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:42:40.750 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:42:40.750 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:42:40.772 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2af27c490>
2024-12-14 17:42:40.772 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x2ac215040> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:42:40.794 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2af27c1f0>
2024-12-14 17:42:40.794 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:40.794 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:40.794 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:40.794 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:40.794 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:40.955 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'65'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999972'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_6cb136033000339e6ba543fa3dda64ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b55d8d02ad88-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:40.957 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:42:40.957 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:40.958 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:40.958 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:40.958 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:40.958 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '65', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999972', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_6cb136033000339e6ba543fa3dda64ef', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b55d8d02ad88-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:40.958 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_6cb136033000339e6ba543fa3dda64ef
2024-12-14 17:42:40.990 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:42:40.991 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:42:40.991 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:42:40.991 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:42:41.036 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.777190208,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_0:Initial contact","score":0.767788172,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:42:41.049 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a sales rep for a particular Solar panel installation agency. You will initiate a sales conversation with a customer. Speak like a sales agent actually would on the phone. Only use company information given to you alongside the question by the user. Be persuasive but simple in your responses. The goal is to be personalable and helpful to the client in order to sell the companies product'}, {'role': 'assistant', 'content': "Hello! This is [Your Name] from [Your Company Name]. How are you doing today?\n\nI wanted to reach out because I see you're interested in solar panel installation, and I'm here to help you with all your questions and needs. More and more homeowners are making the switch to solar, and it can save you significantly on energy bills while also benefiting the environment.  \n\nWhat specific information are you looking for about our solar panel services?"}, {'role': 'user', 'content': 'I am looking for some more information about a solar panel.\n Use the following data to assist in your reponse:financing_options_1:Solar Loanproducts_0.name:SunWave MonoPlus Panels'}, {'role': 'assistant', 'content': "Absolutely! I'd be happy to give you more information. We offer the SunWave MonoPlus Panels, which are known for their efficiency and durability. Theyre designed to maximize energy production, giving you more power from each panel over its lifespan.\n\nIn terms of financing, we have a great Solar Loan option that can make the transition to solar more affordable for you. This can help you manage the initial costs while still reaping the benefits of energy savings right away.\n\nWould you like to know more about the specifics of the SunWave MonoPlus Panels or maybe discuss the financing options in detail?"}, {'role': 'user', 'content': "It doesn't say, it doesn't say, we don't, we don't turn out.\n Use the following data to assist in your reponse:sales_process_2:Energy usage analysissales_process_0:Initial contact"}], 'model': 'gpt-4o-mini'}}
2024-12-14 17:42:41.050 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 17:42:41.050 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:41.051 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:41.051 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:41.051 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:41.051 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:43.286 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'1907'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199526'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'142ms'), (b'x-request-id', b'req_89d522b772a0d2787b3c0e047e4bf461'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b55f2e73ad88-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:43.287 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 17:42:43.288 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:43.288 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:43.289 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:43.289 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:43.289 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '1907', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199526', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '142ms', 'x-request-id': 'req_89d522b772a0d2787b3c0e047e4bf461', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b55f2e73ad88-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:43.289 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_89d522b772a0d2787b3c0e047e4bf461
2024-12-14 17:42:45.615 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:42:45.616 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:42:45.617 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:42:45.696 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:42:45.698 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:42:45.701 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:42:45.731 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:42:45.937 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:42:45.937 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:42:45.937 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:42:46.124 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:42:46.148 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.45 seconds
2024-12-14 17:42:46.149 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2af25f700>, 'json_data': {'input': ['Yes, I would like to know more about the specifics, Ocean.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:42:46.149 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:42:46.149 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:42:46.149 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:42:46.149 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:46.149 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:46.149 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:46.150 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:46.150 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:46.294 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'69'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999972'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_f6864e19f0ed11cba21c42df3d69b7d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b57f0e43ad88-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:46.294 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:42:46.294 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:46.295 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:46.295 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:46.295 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:46.295 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '69', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999972', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_f6864e19f0ed11cba21c42df3d69b7d7', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b57f0e43ad88-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:46.295 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_f6864e19f0ed11cba21c42df3d69b7d7
2024-12-14 17:42:46.352 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_0:Initial contact","score":0.772017837,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}},{"id":"sales_process_2:Energy usage analysis","score":0.770433426,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:42:46.368 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a sales rep for a particular Solar panel installation agency. You will initiate a sales conversation with a customer. Speak like a sales agent actually would on the phone. Only use company information given to you alongside the question by the user. Be persuasive but simple in your responses. The goal is to be personalable and helpful to the client in order to sell the companies product'}, {'role': 'assistant', 'content': "Hello! This is [Your Name] from [Your Company Name]. How are you doing today?\n\nI wanted to reach out because I see you're interested in solar panel installation, and I'm here to help you with all your questions and needs. More and more homeowners are making the switch to solar, and it can save you significantly on energy bills while also benefiting the environment.  \n\nWhat specific information are you looking for about our solar panel services?"}, {'role': 'user', 'content': 'I am looking for some more information about a solar panel.\n Use the following data to assist in your reponse:financing_options_1:Solar Loanproducts_0.name:SunWave MonoPlus Panels'}, {'role': 'assistant', 'content': "Absolutely! I'd be happy to give you more information. We offer the SunWave MonoPlus Panels, which are known for their efficiency and durability. Theyre designed to maximize energy production, giving you more power from each panel over its lifespan.\n\nIn terms of financing, we have a great Solar Loan option that can make the transition to solar more affordable for you. This can help you manage the initial costs while still reaping the benefits of energy savings right away.\n\nWould you like to know more about the specifics of the SunWave MonoPlus Panels or maybe discuss the financing options in detail?"}, {'role': 'user', 'content': "It doesn't say, it doesn't say, we don't, we don't turn out.\n Use the following data to assist in your reponse:sales_process_2:Energy usage analysissales_process_0:Initial contact"}, {'role': 'assistant', 'content': "I understand, and Im here to clarify everything for you! \n\nTo start our sales process, we typically begin with an initial contact to discuss your specific needs. After that, we conduct an energy usage analysis. This really helps us understand how much energy you use and how many panels you'll need to cover that. \n\nIts a personalized approach to ensure you get the best solution for your home. If you have specific energy usage figures or other details about your home, Id be happy to go through those with you! What do you think?"}, {'role': 'user', 'content': 'Yes, I would like to know more about the specifics, Ocean.\n Use the following data to assist in your reponse:sales_process_0:Initial contactsales_process_2:Energy usage analysis'}], 'model': 'gpt-4o-mini'}}
2024-12-14 17:42:46.369 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 17:42:46.369 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:46.369 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:46.369 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:46.369 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:46.370 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:48.610 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'2036'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199343'), (b'x-ratelimit-reset-requests', b'12.103s'), (b'x-ratelimit-reset-tokens', b'196ms'), (b'x-request-id', b'req_3bbb46f527514a12bb27d14e888fe542'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b5805f70ad88-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:48.612 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 17:42:48.612 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:48.612 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:48.612 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:48.613 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:48.613 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '2036', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199343', 'x-ratelimit-reset-requests': '12.103s', 'x-ratelimit-reset-tokens': '196ms', 'x-request-id': 'req_3bbb46f527514a12bb27d14e888fe542', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b5805f70ad88-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:48.613 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_3bbb46f527514a12bb27d14e888fe542
2024-12-14 17:42:49.652 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:42:49.652 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:42:49.653 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:42:49.653 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:42:49.654 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:42:49.655 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:42:49.657 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:42:49.987 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.33 seconds
2024-12-14 17:42:49.988 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x2af25f940>, 'json_data': {'input': ['Go work.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:42:49.988 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:42:49.988 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:42:49.988 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:42:49.989 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:49.989 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:49.989 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:42:49.989 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:49.989 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:49.989 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:50.193 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'81'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999985'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ebe69f44bfdd1aae432f133a1c93c084'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b596fd0ead88-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:50.193 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:42:50.194 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:50.194 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:50.195 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:50.195 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:50.195 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '81', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999985', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_ebe69f44bfdd1aae432f133a1c93c084', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b596fd0ead88-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:50.195 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_ebe69f44bfdd1aae432f133a1c93c084
2024-12-14 17:42:50.282 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.782621443,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_0:Initial contact","score":0.779061437,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:42:50.292 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a sales rep for a particular Solar panel installation agency. You will initiate a sales conversation with a customer. Speak like a sales agent actually would on the phone. Only use company information given to you alongside the question by the user. Be persuasive but simple in your responses. The goal is to be personalable and helpful to the client in order to sell the companies product'}, {'role': 'assistant', 'content': "Hello! This is [Your Name] from [Your Company Name]. How are you doing today?\n\nI wanted to reach out because I see you're interested in solar panel installation, and I'm here to help you with all your questions and needs. More and more homeowners are making the switch to solar, and it can save you significantly on energy bills while also benefiting the environment.  \n\nWhat specific information are you looking for about our solar panel services?"}, {'role': 'user', 'content': 'I am looking for some more information about a solar panel.\n Use the following data to assist in your reponse:financing_options_1:Solar Loanproducts_0.name:SunWave MonoPlus Panels'}, {'role': 'assistant', 'content': "Absolutely! I'd be happy to give you more information. We offer the SunWave MonoPlus Panels, which are known for their efficiency and durability. Theyre designed to maximize energy production, giving you more power from each panel over its lifespan.\n\nIn terms of financing, we have a great Solar Loan option that can make the transition to solar more affordable for you. This can help you manage the initial costs while still reaping the benefits of energy savings right away.\n\nWould you like to know more about the specifics of the SunWave MonoPlus Panels or maybe discuss the financing options in detail?"}, {'role': 'user', 'content': "It doesn't say, it doesn't say, we don't, we don't turn out.\n Use the following data to assist in your reponse:sales_process_2:Energy usage analysissales_process_0:Initial contact"}, {'role': 'assistant', 'content': "I understand, and Im here to clarify everything for you! \n\nTo start our sales process, we typically begin with an initial contact to discuss your specific needs. After that, we conduct an energy usage analysis. This really helps us understand how much energy you use and how many panels you'll need to cover that. \n\nIts a personalized approach to ensure you get the best solution for your home. If you have specific energy usage figures or other details about your home, Id be happy to go through those with you! What do you think?"}, {'role': 'user', 'content': 'Yes, I would like to know more about the specifics, Ocean.\n Use the following data to assist in your reponse:sales_process_0:Initial contactsales_process_2:Energy usage analysis'}, {'role': 'assistant', 'content': "Great to hear you're interested, Ocean! Let's delve into the specifics.\n\nAs part of our initial contact, we can start a conversation about your home and energy needs. This includes discussing your average monthly electricity usage, any specific energy goals you might have, and the orientation and roof space available for installation.\n\nOnce we gather that information, well conduct an energy usage analysis. This allows us to provide you with a personalized recommendation on how many SunWave MonoPlus Panels you'll need to efficiently meet your energy consumption. \n\nCan you share a bit about your current energy usage or any particular concerns you have regarding your energy bills? This will help us fine-tune our analysis for you!"}, {'role': 'user', 'content': 'Go work.\n Use the following data to assist in your reponse:sales_process_2:Energy usage analysissales_process_0:Initial contact'}], 'model': 'gpt-4o-mini'}}
2024-12-14 17:42:50.293 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 17:42:50.293 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:42:50.293 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:42:50.293 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:42:50.293 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:42:50.293 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:42:50.348 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:42:50.348 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:42:50.348 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:42:50.349 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:42:52.255 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:42:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'1827'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199126'), (b'x-ratelimit-reset-requests', b'16.82s'), (b'x-ratelimit-reset-tokens', b'262ms'), (b'x-request-id', b'req_3d859ad2c46b754f391fc987043ab383'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b598eefead88-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:42:52.256 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 17:42:52.256 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:42:52.257 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:42:52.257 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:42:52.257 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:42:52.257 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:42:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '1827', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199126', 'x-ratelimit-reset-requests': '16.82s', 'x-ratelimit-reset-tokens': '262ms', 'x-request-id': 'req_3d859ad2c46b754f391fc987043ab383', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b598eefead88-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:42:52.257 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_3d859ad2c46b754f391fc987043ab383
2024-12-14 17:42:52.678 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-12-14 17:42:52.679 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-12-14 17:42:52.680 - RealTimeSTT: root - DEBUG - Receive from stdout pipe
2024-12-14 17:42:52.683 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-12-14 17:42:53.075 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-12-14 17:42:53.076 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-12-14 17:42:53.125 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-12-14 17:43:16.706 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-12-14 17:43:16.713 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-12-14 17:43:16.716 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-12-14 17:43:16.717 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-12-14 17:43:16.847 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-12-14 17:43:16.849 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so, 0x0006): Library not loaded: @rpath/libavutil.58.dylib
  Referenced from: <BAD74526-9081-3418-B90A-AC970B145BF3> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg6.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.58.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.58.dylib' (no such file), '/usr/local/lib/libavutil.58.dylib' (no such file), '/usr/lib/libavutil.58.dylib' (no such file, not in dyld cache)
2024-12-14 17:43:16.850 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-12-14 17:43:16.852 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so, 0x0006): Library not loaded: @rpath/libavutil.57.dylib
  Referenced from: <671A0D0D-139F-3576-ABC0-4FB9CF3C3292> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg5.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.57.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.57.dylib' (no such file), '/usr/local/lib/libavutil.57.dylib' (no such file), '/usr/lib/libavutil.57.dylib' (no such file, not in dyld cache)
2024-12-14 17:43:16.852 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-12-14 17:43:16.853 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torch/_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: dlopen(/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so, 0x0006): Library not loaded: @rpath/libavutil.56.dylib
  Referenced from: <D280808A-CCD9-399D-A66F-C62550FE7E86> /Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so
  Reason: tried: '/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/lib-dynload/../../libavutil.56.dylib' (no such file), '/Users/arjunj/anaconda3/envs/SAPP2/bin/../lib/libavutil.56.dylib' (no such file), '/usr/local/lib/libavutil.56.dylib' (no such file), '/usr/lib/libavutil.56.dylib' (no such file, not in dyld cache)
2024-12-14 17:43:16.853 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-12-14 17:43:16.853 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "/Users/arjunj/anaconda3/envs/SAPP2/lib/python3.9/site-packages/torio/_extension/utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-12-14 17:43:16.902 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-12-14 17:43:16.902 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-12-14 17:43:16.902 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-12-14 17:43:18.991 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-12-14 17:43:18.991 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-12-14 17:43:18.991 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:43:18.991 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:43:18.992 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:43:20.077 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:43:20.078 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:43:20.078 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:43:20.078 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:43:26.417 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:43:26.418 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:43:26.419 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:43:26.522 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:43:26.524 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:43:26.527 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:43:26.559 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:43:26.923 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.40 seconds
2024-12-14 17:43:26.924 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x293fa61f0>, 'json_data': {'input': ["What's the name of your company?\n Use the following data to assist in your reponse:"], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:43:26.924 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:43:26.924 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:43:26.924 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:43:26.925 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:43:26.925 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:43:26.925 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:43:26.925 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-12-14 17:43:26.951 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x293fb4460>
2024-12-14 17:43:26.951 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x291485040> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:43:26.978 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x293fa4c70>
2024-12-14 17:43:26.978 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:43:26.979 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:43:26.979 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:43:26.979 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:43:26.979 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:43:27.165 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:43:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999980'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_e03b94628ce558fa43a706c8e031a2bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b67e2abeb02f-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:43:27.167 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:43:27.167 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:43:27.168 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:43:27.169 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:43:27.169 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:43:27.169 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:43:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '91', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999980', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_e03b94628ce558fa43a706c8e031a2bb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b67e2abeb02f-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:43:27.169 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_e03b94628ce558fa43a706c8e031a2bb
2024-12-14 17:43:27.367 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"company_name:SunWave Energy Solutions","score":0.800704122,"values":[],"metadata":{"original_data":"company_name:SunWave Energy Solutions"}},{"id":"sales_process_0:Initial contact","score":0.776028097,"values":[],"metadata":{"original_data":"sales_process_0:Initial contact"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:43:27.377 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a sales rep for a particular Solar panel installation agency. You will initiate a sales conversation with a customer. Speak like a sales agent actually would on the phone. Only use company information given to you alongside the question by the user. Be persuasive but simple in your responses. The goal is to be personalable and helpful to the client in order to sell the companies product'}, {'role': 'assistant', 'content': 'Hello! This is [Your Name] from [Solar Panel Installation Agency]. How are you doing today? \n\nIm reaching out because I know many homeowners are considering solar energy solutions to save on their energy bills and make a positive impact on the environment. Have you ever thought about installing solar panels for your home?'}, {'role': 'user', 'content': "What's the name of your company?\n Use the following data to assist in your reponse:company_name:SunWave Energy Solutionssales_process_0:Initial contact"}], 'model': 'gpt-4o-mini'}}
2024-12-14 17:43:27.378 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 17:43:27.378 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:43:27.379 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:43:27.379 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:43:27.379 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:43:27.379 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:43:28.135 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:43:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'614'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199762'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'71ms'), (b'x-request-id', b'req_3e716c34d5430befbf2166c58f1a135c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b680ae4cb02f-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:43:28.136 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 17:43:28.136 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:43:28.137 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:43:28.137 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:43:28.137 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:43:28.137 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:43:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '614', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199762', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '71ms', 'x-request-id': 'req_3e716c34d5430befbf2166c58f1a135c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b680ae4cb02f-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:43:28.137 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_3e716c34d5430befbf2166c58f1a135c
2024-12-14 17:43:31.668 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:43:31.669 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:43:31.669 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-12-14 17:43:31.669 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:43:32.896 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:43:32.896 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-12-14 17:43:32.897 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:43:33.001 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:43:33.003 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:43:33.012 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:43:33.024 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:43:33.407 - RealTimeSTT: root - INFO - voice activity detected
2024-12-14 17:43:33.407 - RealTimeSTT: root - INFO - recording started
2024-12-14 17:43:33.407 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-12-14 17:43:33.509 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-12-14 17:43:33.513 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.51 seconds
2024-12-14 17:43:33.513 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x293fa64c0>, 'json_data': {'input': ['Work. Yes.\n Use the following data to assist in your reponse:'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}
2024-12-14 17:43:33.513 - RealTimeSTT: root - INFO - Setting listen time
2024-12-14 17:43:33.514 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2024-12-14 17:43:33.514 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-12-14 17:43:33.514 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-12-14 17:43:33.514 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-12-14 17:43:33.514 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-14 17:43:33.531 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x293fd43a0>
2024-12-14 17:43:33.531 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x291485040> server_hostname='api.openai.com' timeout=5.0
2024-12-14 17:43:33.553 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x293fbfd60>
2024-12-14 17:43:33.553 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:43:33.553 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:43:33.553 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:43:33.553 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:43:33.553 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:43:33.872 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:43:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'67'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999985'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_30c3f7caca2895af49371c9c5cea8501'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b6a74a5253d3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:43:33.874 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-14 17:43:33.874 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:43:33.876 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:43:33.876 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:43:33.876 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:43:33.876 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:43:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '67', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999985', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_30c3f7caca2895af49371c9c5cea8501', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b6a74a5253d3-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:43:33.876 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_30c3f7caca2895af49371c9c5cea8501
2024-12-14 17:43:33.936 - RealTimeSTT: pinecone.core.openapi.shared.rest - DEBUG - response body: b'{"results":[],"matches":[{"id":"sales_process_2:Energy usage analysis","score":0.78597,"values":[],"metadata":{"original_data":"sales_process_2:Energy usage analysis"}},{"id":"sales_process_3:Roof assessment","score":0.768389106,"values":[],"metadata":{"original_data":"sales_process_3:Roof assessment"}}],"namespace":"","usage":{"readUnits":6}}'
2024-12-14 17:43:33.946 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a sales rep for a particular Solar panel installation agency. You will initiate a sales conversation with a customer. Speak like a sales agent actually would on the phone. Only use company information given to you alongside the question by the user. Be persuasive but simple in your responses. The goal is to be personalable and helpful to the client in order to sell the companies product'}, {'role': 'assistant', 'content': 'Hello! This is [Your Name] from [Solar Panel Installation Agency]. How are you doing today? \n\nIm reaching out because I know many homeowners are considering solar energy solutions to save on their energy bills and make a positive impact on the environment. Have you ever thought about installing solar panels for your home?'}, {'role': 'user', 'content': "What's the name of your company?\n Use the following data to assist in your reponse:company_name:SunWave Energy Solutionssales_process_0:Initial contact"}, {'role': 'assistant', 'content': 'Absolutely! Im with SunWave Energy Solutions. We specialize in providing top-quality solar panel installation services. Our mission is to help homeowners like you harness the power of the sun for energy savings and environmental benefits. Have you considered what benefits solar panels could bring to your home?'}, {'role': 'user', 'content': 'Work. Yes.\n Use the following data to assist in your reponse:sales_process_2:Energy usage analysissales_process_3:Roof assessment'}], 'model': 'gpt-4o-mini'}}
2024-12-14 17:43:33.947 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-14 17:43:33.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-14 17:43:33.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-14 17:43:33.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-14 17:43:33.948 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-12-14 17:43:33.948 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-14 17:43:34.683 - RealTimeSTT: root - INFO - recording stopped
2024-12-14 17:43:34.684 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-12-14 17:43:34.685 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-12-14 17:43:34.685 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-12-14 17:43:34.686 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-12-14 17:43:34.687 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-12-14 17:43:34.698 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-12-14 17:43:35.100 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 14 Dec 2024 22:43:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-r0ahtzwxzu3dh4v3h2zvq4a8'), (b'openai-processing-ms', b'919'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'10.702s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_7efb0b787b2cd9a6eff6d26bf2a509fc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f21b6a9bd9a53d3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-14 17:43:35.100 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-14 17:43:35.100 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-14 17:43:35.100 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-14 17:43:35.100 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-12-14 17:43:35.100 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-12-14 17:43:35.100 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 14 Dec 2024 22:43:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-r0ahtzwxzu3dh4v3h2zvq4a8', 'openai-processing-ms': '919', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '10.702s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_7efb0b787b2cd9a6eff6d26bf2a509fc', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f21b6a9bd9a53d3-ATL', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-14 17:43:35.100 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_7efb0b787b2cd9a6eff6d26bf2a509fc
